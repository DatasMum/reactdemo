{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Retrain-Object-Detection_ssd_mobilenetv2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DatasMum/reactdemo/blob/main/Retrain_Object_Detection_ssd_mobilenetv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF8ysCfYKgTP"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "In this notebook, we implement [The TensorFlow 2 Object Detection Library](https://blog.tensorflow.org/2020/07/tensorflow-2-meets-object-detection-api.html) for training on your own dataset.\n",
        "\n",
        "\n",
        "We will take the following steps to implement mobilenetV2 on our custom data:\n",
        "* Install TensorFlow2 Object Detection Dependencies\n",
        "* Download Custom TensorFlow2 Object Detection Dataset\n",
        "* Write Custom TensorFlow2 Object Detection Training Configuation\n",
        "* Train Custom TensorFlow2 Object Detection Model\n",
        "* Export Custom TensorFlow2 Object Detection Weights\n",
        "* Use Trained TensorFlow2 Object Detection For Inference on Test Images\n",
        "\n",
        "When you are done you will have a custom detector that you can use. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7EOtpvlLeS0"
      },
      "source": [
        "# Install TensorFlow2 Object Detection Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypWGYdPlLRUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27eaf65-31aa-44ea-c5c8-119c5eb91ad3"
      },
      "source": [
        "#Clone rep of TensorFlow object detection api \n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3157, done.\u001b[K\n",
            "remote: Counting objects: 100% (3157/3157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2490/2490), done.\u001b[K\n",
            "remote: Total 3157 (delta 836), reused 1498 (delta 623), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3157/3157), 33.37 MiB | 18.43 MiB/s, done.\n",
            "Resolving deltas: 100% (836/836), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QPmVBSlLTzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64dcc2b-9722-4d7c-d6a5-3d1ee34f6704"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd /content/models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.35.0-cp37-cp37m-manylinux2010_x86_64.whl (9.9 MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.26)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.10)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting tensorflow-text>=2.7.0\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.23.1)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.43.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.19.9-py3-none-any.whl (45 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.6-cp37-cp37m-manylinux_2_24_x86_64.whl (245 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.11)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.6.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1684828 sha256=76f89e585d3dfa3bd95ad483ff43eb5ed5ebee87d7c7f152b2c728e1ab97f209\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0hdt40eo/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for py-cpuinfo (setup.py): started\n",
            "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=870aa9cabf811619c4de1bf3f27767ddec65a87ff249d1bf97be424a428474bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=15b5662eeb9e255e1fd354d19e0f42a94e5b9849642ab2b8816298d62e18cb5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=1eb382fb8cdebe2908353ad962efe9edfb4806e85bb6ab01a0412ec7a46f73e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=aa8aa2ed4944d571a363da9f8785f2146f28f68c5ab0860a85944650a11ad54b\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, protobuf, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.0.1\n",
            "    Uninstalling pymongo-4.0.1:\n",
            "      Successfully uninstalled pymongo-4.0.1\n",
            "Successfully installed apache-beam-2.35.0 avro-python3-1.10.2 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.9 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.62 orjson-3.6.6 portalocker-2.3.2 proto-plus-1.19.9 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-6.0 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.15.0 tensorflow-io-0.23.1 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 tf-models-official-2.7.0 tf-slim-1.1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHfsJ5nWLWh9"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh_HPMOqWH9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f9a863-4b7b-4651-c830-4641e57d0512"
      },
      "source": [
        "#run model builder test\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.7.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-02-02 06:08:17.228739: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0202 06:08:17.576105 140338018654080 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.74s\n",
            "I0202 06:08:17.836381 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.74s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "I0202 06:08:18.338307 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.26s\n",
            "I0202 06:08:18.599134 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n",
            "I0202 06:08:18.845046 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.66s\n",
            "I0202 06:08:20.504377 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.66s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0202 06:08:20.505331 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0202 06:08:20.527658 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0202 06:08:20.541048 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0202 06:08:20.555311 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I0202 06:08:20.648305 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n",
            "I0202 06:08:20.747506 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I0202 06:08:20.841769 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I0202 06:08:20.934088 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "I0202 06:08:21.025647 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0202 06:08:21.060788 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0202 06:08:21.226688 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0202 06:08:21.226827 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0202 06:08:21.226897 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0202 06:08:21.228923 140338018654080 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0202 06:08:21.243739 140338018654080 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0202 06:08:21.243856 140338018654080 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0202 06:08:21.294479 140338018654080 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0202 06:08:21.294596 140338018654080 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0202 06:08:21.430243 140338018654080 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0202 06:08:21.430363 140338018654080 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0202 06:08:21.563970 140338018654080 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0202 06:08:21.564115 140338018654080 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0202 06:08:21.902041 140338018654080 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0202 06:08:21.902247 140338018654080 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0202 06:08:22.103050 140338018654080 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0202 06:08:22.103221 140338018654080 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0202 06:08:22.380085 140338018654080 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0202 06:08:22.380256 140338018654080 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0202 06:08:22.445162 140338018654080 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0202 06:08:22.470996 140338018654080 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0202 06:08:22.520001 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0202 06:08:22.520147 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0202 06:08:22.520235 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0202 06:08:22.521793 140338018654080 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0202 06:08:22.535230 140338018654080 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0202 06:08:22.535344 140338018654080 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0202 06:08:22.644752 140338018654080 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0202 06:08:22.644877 140338018654080 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0202 06:08:22.850638 140338018654080 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0202 06:08:22.850811 140338018654080 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0202 06:08:23.055368 140338018654080 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0202 06:08:23.055534 140338018654080 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0202 06:08:23.322237 140338018654080 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0202 06:08:23.322419 140338018654080 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0202 06:08:23.592770 140338018654080 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0202 06:08:23.592928 140338018654080 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0202 06:08:23.934869 140338018654080 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0202 06:08:23.935034 140338018654080 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0202 06:08:24.065681 140338018654080 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0202 06:08:24.091789 140338018654080 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0202 06:08:24.150401 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0202 06:08:24.150560 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0202 06:08:24.150631 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0202 06:08:24.152459 140338018654080 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0202 06:08:24.166274 140338018654080 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0202 06:08:24.166382 140338018654080 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0202 06:08:24.274914 140338018654080 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0202 06:08:24.275035 140338018654080 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0202 06:08:24.477037 140338018654080 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0202 06:08:24.477201 140338018654080 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0202 06:08:24.683557 140338018654080 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0202 06:08:24.683720 140338018654080 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0202 06:08:24.959724 140338018654080 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0202 06:08:24.959885 140338018654080 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0202 06:08:25.224298 140338018654080 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0202 06:08:25.224464 140338018654080 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0202 06:08:25.729196 140338018654080 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0202 06:08:25.729398 140338018654080 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0202 06:08:25.866099 140338018654080 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0202 06:08:25.891941 140338018654080 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0202 06:08:25.952242 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0202 06:08:25.952383 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0202 06:08:25.952458 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0202 06:08:25.954078 140338018654080 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0202 06:08:25.967830 140338018654080 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0202 06:08:25.967953 140338018654080 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0202 06:08:26.073124 140338018654080 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0202 06:08:26.073252 140338018654080 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0202 06:08:26.274194 140338018654080 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0202 06:08:26.274333 140338018654080 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0202 06:08:26.473613 140338018654080 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0202 06:08:26.473779 140338018654080 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0202 06:08:26.820952 140338018654080 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0202 06:08:26.821134 140338018654080 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0202 06:08:27.161941 140338018654080 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0202 06:08:27.162131 140338018654080 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0202 06:08:27.565206 140338018654080 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0202 06:08:27.565372 140338018654080 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0202 06:08:27.697368 140338018654080 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0202 06:08:27.721999 140338018654080 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0202 06:08:27.786306 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0202 06:08:27.786443 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0202 06:08:27.786516 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0202 06:08:27.788472 140338018654080 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0202 06:08:27.802536 140338018654080 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0202 06:08:27.802648 140338018654080 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0202 06:08:27.915340 140338018654080 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0202 06:08:27.915469 140338018654080 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0202 06:08:28.196598 140338018654080 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0202 06:08:28.196789 140338018654080 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0202 06:08:28.478046 140338018654080 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0202 06:08:28.478220 140338018654080 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0202 06:08:28.891022 140338018654080 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0202 06:08:28.891203 140338018654080 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0202 06:08:29.290014 140338018654080 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0202 06:08:29.290186 140338018654080 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0202 06:08:29.832212 140338018654080 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0202 06:08:29.832388 140338018654080 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0202 06:08:30.177844 140338018654080 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0202 06:08:30.202954 140338018654080 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0202 06:08:30.275088 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0202 06:08:30.275261 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0202 06:08:30.275339 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0202 06:08:30.276883 140338018654080 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0202 06:08:30.290164 140338018654080 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0202 06:08:30.290277 140338018654080 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0202 06:08:30.452698 140338018654080 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0202 06:08:30.452837 140338018654080 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0202 06:08:30.791729 140338018654080 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0202 06:08:30.791900 140338018654080 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0202 06:08:31.131386 140338018654080 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0202 06:08:31.131565 140338018654080 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0202 06:08:31.614052 140338018654080 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0202 06:08:31.614231 140338018654080 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0202 06:08:32.089784 140338018654080 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0202 06:08:32.089950 140338018654080 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0202 06:08:32.693513 140338018654080 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0202 06:08:32.693678 140338018654080 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0202 06:08:32.897419 140338018654080 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0202 06:08:32.928772 140338018654080 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0202 06:08:33.015365 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0202 06:08:33.015515 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0202 06:08:33.015589 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0202 06:08:33.017083 140338018654080 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0202 06:08:33.030960 140338018654080 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0202 06:08:33.031077 140338018654080 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0202 06:08:33.188654 140338018654080 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0202 06:08:33.188779 140338018654080 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0202 06:08:33.590704 140338018654080 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0202 06:08:33.590879 140338018654080 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0202 06:08:34.000237 140338018654080 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0202 06:08:34.000401 140338018654080 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0202 06:08:34.536365 140338018654080 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0202 06:08:34.536535 140338018654080 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0202 06:08:35.325563 140338018654080 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0202 06:08:35.325736 140338018654080 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0202 06:08:36.074308 140338018654080 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0202 06:08:36.074472 140338018654080 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0202 06:08:36.274812 140338018654080 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0202 06:08:36.300493 140338018654080 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0202 06:08:36.399439 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0202 06:08:36.399592 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0202 06:08:36.399668 140338018654080 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0202 06:08:36.401251 140338018654080 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0202 06:08:36.415770 140338018654080 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0202 06:08:36.415884 140338018654080 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0202 06:08:36.630967 140338018654080 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0202 06:08:36.631122 140338018654080 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0202 06:08:37.108399 140338018654080 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0202 06:08:37.108564 140338018654080 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0202 06:08:37.592168 140338018654080 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0202 06:08:37.592349 140338018654080 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0202 06:08:38.276898 140338018654080 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0202 06:08:38.277072 140338018654080 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0202 06:08:38.956060 140338018654080 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0202 06:08:38.956261 140338018654080 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0202 06:08:40.085012 140338018654080 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0202 06:08:40.085192 140338018654080 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0202 06:08:40.366084 140338018654080 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0202 06:08:40.391567 140338018654080 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 19.44s\n",
            "I0202 06:08:40.505560 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 19.44s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0202 06:08:40.512309 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0202 06:08:40.513995 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0202 06:08:40.514538 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0202 06:08:40.515989 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0202 06:08:40.517377 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0202 06:08:40.517829 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0202 06:08:40.518749 140338018654080 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 25.423s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPbU4I7aL9Fl"
      },
      "source": [
        "# Prepare Tensorflow 2 Object Detection Training Data\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "\n",
        "We are going to use Roboflow to generate image data set and convert it to TFrecords format.\n",
        "\n",
        "To create a dataset in Roboflow and generate TFRecords, follow [this step-by-step guide](https://blog.roboflow.ai/getting-started-with-roboflow/).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcHJuaurS_AO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5a0b6c-94db-438a-9b7f-c86467d54bc7"
      },
      "source": [
        "#Downloading data Training set made by Roboflow\n",
        "%cd /content\n",
        "\n",
        "#Download Training set from git by cloning rep:\n",
        "import os\n",
        "import pathlib\n",
        "# Clone the training set repository if it doesn't already exist\n",
        "if \"RetrainModelExample\" in pathlib.Path.cwd().parts:\n",
        "  while \"RetrainModelExample\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('RetrainModelExample').exists():\n",
        "  !git clone --depth 1 https://github.com/KostaMalsev/RetrainModelExample\n",
        "  %cd /content/RetrainModelExample/TrainingSet/Picka \n",
        "  !unzip Pickachu2.v1.tfrecord.zip -d /content/\n",
        "\n",
        "#NOTE: Update these TFRecord names to your files containing training set!\n",
        "#Also, Update relevant rows:in training config file \"ssd_mobilenet_v2_320x320_coco17_tpu-8.config\"\n",
        "#label_map_path,input_path \n",
        "test_record_fname = '/content/valid/Cars.tfrecord'\n",
        "train_record_fname = '/content/train/Cars.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/train/Cars_label_map.pbtxt'\n",
        "\n",
        "#test_record_fname = '/content/valid/pieces.tfrecord'\n",
        "#train_record_fname = '/content/train/toymnm.tfrecord'\n",
        "#label_map_pbtxt_fname = '/content/train/toymnm_label_map.pbtxt'\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2MAcgJ53STW"
      },
      "source": [
        "# Configure Custom TensorFlow2 Object Detection Training \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> In this section we specify configuration for mobilentV2 model. for additional models see [TF2 OD model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN0EUEa3e5Un"
      },
      "source": [
        "#We choose mobilentv2 model to deploy from TF2 object detection zoo\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2_320x320_coco17': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "        'batch_size': 16\n",
        "    }\n",
        "}\n",
        "#'batchsize 512 19/10/20\n",
        "chosen_model = 'ssd_mobilenet_v2_320x320_coco17'\n",
        "\n",
        "num_steps = 1800 #40000 #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \n",
        "num_eval_steps = 500 #Perform evaluation after so many steps\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your trainin#g\n",
        "#base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG4TmJUVrYQ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "d13bbe51-6e11-4ba6-fa0f-f6349866caf8"
      },
      "source": [
        "#Download pretrained weights\n",
        "%mkdir /content/deploy/\n",
        "%cd /content/deploy/\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "#Shorten the folder name,because long file paths are not yet supported :(\n",
        "os.rename('ssd_mobilenet_v2_320x320_coco17_tpu-8','mobilnetv2')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/deploy/’: File exists\n",
            "/content/deploy\n",
            "--2022-02-02 06:14:45--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.195.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.195.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46042990 (44M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz.1’\n",
            "\n",
            "ssd_mobilenet_v2_32 100%[===================>]  43.91M   257MB/s    in 0.2s    \n",
            "\n",
            "2022-02-02 06:14:45 (257 MB/s) - ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz.1’ saved [46042990/46042990]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-23e512baf367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Shorten the folder name,because long file paths are not yet supported :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ssd_mobilenet_v2_320x320_coco17_tpu-8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mobilnetv2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: [Errno 39] Directory not empty: 'ssd_mobilenet_v2_320x320_coco17_tpu-8' -> 'mobilnetv2'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-nqYZtdtsgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479e2a73-aa5a-42ec-a580-465ec0b12793"
      },
      "source": [
        "#Download training configuration file for mobilenetV2. \n",
        "#note: configuration file contain references to your trainig set of images,\n",
        "#you can change it for your dataset.\n",
        "%cd /content/deploy\n",
        "download_config = 'https://raw.githubusercontent.com/KostaMalsev/RetrainModelExample/main/ssd_mobilenet_v2_320x320_coco17_tpu-8.config'\n",
        "!wget {download_config}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deploy\n",
            "--2022-02-02 06:10:21--  https://raw.githubusercontent.com/KostaMalsev/RetrainModelExample/main/ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4737 (4.6K) [text/plain]\n",
            "Saving to: ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.config’\n",
            "\n",
            "ssd_mobilenet_v2_32 100%[===================>]   4.63K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-02 06:10:22 (63.3 MB/s) - ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.config’ saved [4737/4737]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_ki9jOqxn7V"
      },
      "source": [
        "#Prepare loaded model for retraining\n",
        "fine_tune_checkpoint = '/content/deploy/mobilnetv2/checkpoint/ckpt-0'\n",
        "pipeline_file = '/content/deploy/ssd_mobilenet_v2_320x320_coco17_tpu-8.config'\n",
        "model_dir = '/content/training/'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGC8QUt5nHkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a255a98-0627-4abf-ace0-cf3c33dadb4c"
      },
      "source": [
        "#Check if all configuration is OK:\n",
        "print(fine_tune_checkpoint)\n",
        "print(train_record_fname)\n",
        "print(label_map_pbtxt_fname)\n",
        "print(batch_size)\n",
        "print(num_steps)\n",
        "print(num_classes)\n",
        "print(pipeline_file)\n",
        "print(model_dir)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deploy/mobilnetv2/checkpoint/ckpt-0\n",
            "/content/train/Cars.tfrecord\n",
            "/content/train/Cars_label_map.pbtxt\n",
            "16\n",
            "1800\n",
            "2\n",
            "/content/deploy/ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
            "/content/training/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxPj_QV43qD5"
      },
      "source": [
        "# Train Custom TF2 Object Detector\n",
        "\n",
        "* pipeline_file: defined above in writing custom training configuration\n",
        "* model_dir: the location tensorboard logs and saved model checkpoints will save to\n",
        "* num_train_steps: how long to train for\n",
        "* num_eval_steps: perform eval on validation set after this many steps\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQTfZChVzzpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de32e832-d5c4-43af-90bb-24ac0532d8f7"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-02 06:18:31.468309: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0202 06:18:31.471405 139685939885952 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 1800\n",
            "I0202 06:18:31.475993 139685939885952 config_util.py:552] Maybe overwriting train_steps: 1800\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0202 06:18:31.476160 139685939885952 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0202 06:18:31.520947 139685939885952 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/train/Cars.tfrecord']\n",
            "I0202 06:18:31.532098 139685939885952 dataset_builder.py:163] Reading unweighted datasets: ['/content/train/Cars.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/train/Cars.tfrecord']\n",
            "I0202 06:18:31.532301 139685939885952 dataset_builder.py:80] Reading record datasets for input file: ['/content/train/Cars.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0202 06:18:31.532393 139685939885952 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0202 06:18:31.532470 139685939885952 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0202 06:18:31.537872 139685939885952 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0202 06:18:31.562206 139685939885952 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0202 06:18:38.621159 139685939885952 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0202 06:18:42.137734 139685939885952 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0202 06:18:44.893855 139685939885952 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:18:54.575490 139680803677952 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:18:54.575785 139680803677952 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:18:54.575945 139680803677952 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:18:54.576095 139680803677952 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:18:54.576249 139680803677952 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:18:54.576390 139680803677952 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0202 06:19:20.024961 139685939885952 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0202 06:19:20.026235 139685939885952 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0202 06:19:20.028255 139685939885952 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0202 06:19:20.029114 139685939885952 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0202 06:19:20.031076 139685939885952 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0202 06:19:20.031939 139685939885952 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0202 06:19:20.033950 139685939885952 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0202 06:19:20.035004 139685939885952 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0202 06:19:20.037001 139685939885952 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0202 06:19:20.037880 139685939885952 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0202 06:19:20.610264 139680728143616 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.589s\n",
            "I0202 06:20:19.155189 139685939885952 model_lib_v2.py:707] Step 100 per-step time 0.589s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.6248863,\n",
            " 'Loss/localization_loss': 0.9971539,\n",
            " 'Loss/regularization_loss': 1.113695,\n",
            " 'Loss/total_loss': 2.7357352,\n",
            " 'learning_rate': 0.1666635}\n",
            "I0202 06:20:19.155507 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.6248863,\n",
            " 'Loss/localization_loss': 0.9971539,\n",
            " 'Loss/regularization_loss': 1.113695,\n",
            " 'Loss/total_loss': 2.7357352,\n",
            " 'learning_rate': 0.1666635}\n",
            "INFO:tensorflow:Step 200 per-step time 0.219s\n",
            "I0202 06:20:41.086869 139685939885952 model_lib_v2.py:707] Step 200 per-step time 0.219s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4558807,\n",
            " 'Loss/localization_loss': 0.9396745,\n",
            " 'Loss/regularization_loss': 1.0981941,\n",
            " 'Loss/total_loss': 2.4937494,\n",
            " 'learning_rate': 0.19999701}\n",
            "I0202 06:20:41.087185 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.4558807,\n",
            " 'Loss/localization_loss': 0.9396745,\n",
            " 'Loss/regularization_loss': 1.0981941,\n",
            " 'Loss/total_loss': 2.4937494,\n",
            " 'learning_rate': 0.19999701}\n",
            "INFO:tensorflow:Step 300 per-step time 0.218s\n",
            "I0202 06:21:02.893980 139685939885952 model_lib_v2.py:707] Step 300 per-step time 0.218s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.28820312,\n",
            " 'Loss/localization_loss': 0.9101839,\n",
            " 'Loss/regularization_loss': 1.0801575,\n",
            " 'Loss/total_loss': 2.2785444,\n",
            " 'learning_rate': 0.23333052}\n",
            "I0202 06:21:02.894280 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.28820312,\n",
            " 'Loss/localization_loss': 0.9101839,\n",
            " 'Loss/regularization_loss': 1.0801575,\n",
            " 'Loss/total_loss': 2.2785444,\n",
            " 'learning_rate': 0.23333052}\n",
            "INFO:tensorflow:Step 400 per-step time 0.221s\n",
            "I0202 06:21:24.975391 139685939885952 model_lib_v2.py:707] Step 400 per-step time 0.221s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.30364156,\n",
            " 'Loss/localization_loss': 0.6929653,\n",
            " 'Loss/regularization_loss': 1.0602669,\n",
            " 'Loss/total_loss': 2.0568738,\n",
            " 'learning_rate': 0.26666403}\n",
            "I0202 06:21:24.975780 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.30364156,\n",
            " 'Loss/localization_loss': 0.6929653,\n",
            " 'Loss/regularization_loss': 1.0602669,\n",
            " 'Loss/total_loss': 2.0568738,\n",
            " 'learning_rate': 0.26666403}\n",
            "INFO:tensorflow:Step 500 per-step time 0.222s\n",
            "I0202 06:21:47.166770 139685939885952 model_lib_v2.py:707] Step 500 per-step time 0.222s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24001114,\n",
            " 'Loss/localization_loss': 0.5962906,\n",
            " 'Loss/regularization_loss': 1.0381744,\n",
            " 'Loss/total_loss': 1.8744762,\n",
            " 'learning_rate': 0.2999975}\n",
            "I0202 06:21:47.167065 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.24001114,\n",
            " 'Loss/localization_loss': 0.5962906,\n",
            " 'Loss/regularization_loss': 1.0381744,\n",
            " 'Loss/total_loss': 1.8744762,\n",
            " 'learning_rate': 0.2999975}\n",
            "INFO:tensorflow:Step 600 per-step time 0.220s\n",
            "I0202 06:22:09.166221 139685939885952 model_lib_v2.py:707] Step 600 per-step time 0.220s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25892934,\n",
            " 'Loss/localization_loss': 0.49605295,\n",
            " 'Loss/regularization_loss': 1.0142123,\n",
            " 'Loss/total_loss': 1.7691946,\n",
            " 'learning_rate': 0.33333102}\n",
            "I0202 06:22:09.166505 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.25892934,\n",
            " 'Loss/localization_loss': 0.49605295,\n",
            " 'Loss/regularization_loss': 1.0142123,\n",
            " 'Loss/total_loss': 1.7691946,\n",
            " 'learning_rate': 0.33333102}\n",
            "INFO:tensorflow:Step 700 per-step time 0.225s\n",
            "I0202 06:22:31.642332 139685939885952 model_lib_v2.py:707] Step 700 per-step time 0.225s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21316357,\n",
            " 'Loss/localization_loss': 0.5122172,\n",
            " 'Loss/regularization_loss': 0.98868275,\n",
            " 'Loss/total_loss': 1.7140635,\n",
            " 'learning_rate': 0.36666453}\n",
            "I0202 06:22:31.642628 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.21316357,\n",
            " 'Loss/localization_loss': 0.5122172,\n",
            " 'Loss/regularization_loss': 0.98868275,\n",
            " 'Loss/total_loss': 1.7140635,\n",
            " 'learning_rate': 0.36666453}\n",
            "INFO:tensorflow:Step 800 per-step time 0.219s\n",
            "I0202 06:22:53.591606 139685939885952 model_lib_v2.py:707] Step 800 per-step time 0.219s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1813068,\n",
            " 'Loss/localization_loss': 0.36956954,\n",
            " 'Loss/regularization_loss': 0.96133417,\n",
            " 'Loss/total_loss': 1.5122105,\n",
            " 'learning_rate': 0.399998}\n",
            "I0202 06:22:53.591902 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.1813068,\n",
            " 'Loss/localization_loss': 0.36956954,\n",
            " 'Loss/regularization_loss': 0.96133417,\n",
            " 'Loss/total_loss': 1.5122105,\n",
            " 'learning_rate': 0.399998}\n",
            "INFO:tensorflow:Step 900 per-step time 0.221s\n",
            "I0202 06:23:15.736835 139685939885952 model_lib_v2.py:707] Step 900 per-step time 0.221s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21014306,\n",
            " 'Loss/localization_loss': 0.37530154,\n",
            " 'Loss/regularization_loss': 0.93245775,\n",
            " 'Loss/total_loss': 1.5179024,\n",
            " 'learning_rate': 0.4333315}\n",
            "I0202 06:23:15.737139 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.21014306,\n",
            " 'Loss/localization_loss': 0.37530154,\n",
            " 'Loss/regularization_loss': 0.93245775,\n",
            " 'Loss/total_loss': 1.5179024,\n",
            " 'learning_rate': 0.4333315}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.224s\n",
            "I0202 06:23:38.106834 139685939885952 model_lib_v2.py:707] Step 1000 per-step time 0.224s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14421085,\n",
            " 'Loss/localization_loss': 0.31362683,\n",
            " 'Loss/regularization_loss': 0.902378,\n",
            " 'Loss/total_loss': 1.3602157,\n",
            " 'learning_rate': 0.46666503}\n",
            "I0202 06:23:38.107137 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.14421085,\n",
            " 'Loss/localization_loss': 0.31362683,\n",
            " 'Loss/regularization_loss': 0.902378,\n",
            " 'Loss/total_loss': 1.3602157,\n",
            " 'learning_rate': 0.46666503}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.227s\n",
            "I0202 06:24:00.839451 139685939885952 model_lib_v2.py:707] Step 1100 per-step time 0.227s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16448018,\n",
            " 'Loss/localization_loss': 0.36489016,\n",
            " 'Loss/regularization_loss': 0.87121403,\n",
            " 'Loss/total_loss': 1.4005843,\n",
            " 'learning_rate': 0.4999985}\n",
            "I0202 06:24:00.839763 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.16448018,\n",
            " 'Loss/localization_loss': 0.36489016,\n",
            " 'Loss/regularization_loss': 0.87121403,\n",
            " 'Loss/total_loss': 1.4005843,\n",
            " 'learning_rate': 0.4999985}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.223s\n",
            "I0202 06:24:23.144123 139685939885952 model_lib_v2.py:707] Step 1200 per-step time 0.223s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16165589,\n",
            " 'Loss/localization_loss': 0.29848805,\n",
            " 'Loss/regularization_loss': 0.8390654,\n",
            " 'Loss/total_loss': 1.2992094,\n",
            " 'learning_rate': 0.53333205}\n",
            "I0202 06:24:23.144423 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.16165589,\n",
            " 'Loss/localization_loss': 0.29848805,\n",
            " 'Loss/regularization_loss': 0.8390654,\n",
            " 'Loss/total_loss': 1.2992094,\n",
            " 'learning_rate': 0.53333205}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.222s\n",
            "I0202 06:24:45.317891 139685939885952 model_lib_v2.py:707] Step 1300 per-step time 0.222s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17222728,\n",
            " 'Loss/localization_loss': 0.43120477,\n",
            " 'Loss/regularization_loss': 0.8065435,\n",
            " 'Loss/total_loss': 1.4099755,\n",
            " 'learning_rate': 0.56666553}\n",
            "I0202 06:24:45.318194 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.17222728,\n",
            " 'Loss/localization_loss': 0.43120477,\n",
            " 'Loss/regularization_loss': 0.8065435,\n",
            " 'Loss/total_loss': 1.4099755,\n",
            " 'learning_rate': 0.56666553}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.223s\n",
            "I0202 06:25:07.582298 139685939885952 model_lib_v2.py:707] Step 1400 per-step time 0.223s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12124043,\n",
            " 'Loss/localization_loss': 0.22135393,\n",
            " 'Loss/regularization_loss': 0.7735967,\n",
            " 'Loss/total_loss': 1.116191,\n",
            " 'learning_rate': 0.599999}\n",
            "I0202 06:25:07.582626 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.12124043,\n",
            " 'Loss/localization_loss': 0.22135393,\n",
            " 'Loss/regularization_loss': 0.7735967,\n",
            " 'Loss/total_loss': 1.116191,\n",
            " 'learning_rate': 0.599999}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.228s\n",
            "I0202 06:25:30.399559 139685939885952 model_lib_v2.py:707] Step 1500 per-step time 0.228s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11860863,\n",
            " 'Loss/localization_loss': 0.21959151,\n",
            " 'Loss/regularization_loss': 0.7401618,\n",
            " 'Loss/total_loss': 1.078362,\n",
            " 'learning_rate': 0.6333325}\n",
            "I0202 06:25:30.399853 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.11860863,\n",
            " 'Loss/localization_loss': 0.21959151,\n",
            " 'Loss/regularization_loss': 0.7401618,\n",
            " 'Loss/total_loss': 1.078362,\n",
            " 'learning_rate': 0.6333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.228s\n",
            "I0202 06:25:53.161625 139685939885952 model_lib_v2.py:707] Step 1600 per-step time 0.228s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20487127,\n",
            " 'Loss/localization_loss': 0.21545143,\n",
            " 'Loss/regularization_loss': 0.7065364,\n",
            " 'Loss/total_loss': 1.1268592,\n",
            " 'learning_rate': 0.66666603}\n",
            "I0202 06:25:53.161930 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.20487127,\n",
            " 'Loss/localization_loss': 0.21545143,\n",
            " 'Loss/regularization_loss': 0.7065364,\n",
            " 'Loss/total_loss': 1.1268592,\n",
            " 'learning_rate': 0.66666603}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.224s\n",
            "I0202 06:26:15.579727 139685939885952 model_lib_v2.py:707] Step 1700 per-step time 0.224s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19414668,\n",
            " 'Loss/localization_loss': 0.27703348,\n",
            " 'Loss/regularization_loss': 0.6734037,\n",
            " 'Loss/total_loss': 1.1445838,\n",
            " 'learning_rate': 0.6999995}\n",
            "I0202 06:26:15.580003 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.19414668,\n",
            " 'Loss/localization_loss': 0.27703348,\n",
            " 'Loss/regularization_loss': 0.6734037,\n",
            " 'Loss/total_loss': 1.1445838,\n",
            " 'learning_rate': 0.6999995}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.225s\n",
            "I0202 06:26:38.096005 139685939885952 model_lib_v2.py:707] Step 1800 per-step time 0.225s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16550231,\n",
            " 'Loss/localization_loss': 0.2598642,\n",
            " 'Loss/regularization_loss': 0.6405845,\n",
            " 'Loss/total_loss': 1.0659511,\n",
            " 'learning_rate': 0.733333}\n",
            "I0202 06:26:38.096313 139685939885952 model_lib_v2.py:708] {'Loss/classification_loss': 0.16550231,\n",
            " 'Loss/localization_loss': 0.2598642,\n",
            " 'Loss/regularization_loss': 0.6405845,\n",
            " 'Loss/total_loss': 1.0659511,\n",
            " 'learning_rate': 0.733333}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless==4.1.2.30 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR6AGpC6FPR9",
        "outputId": "4c3cc993-90c9-4f4c-f741-caabfc3a525f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless==4.1.2.30 in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqaZ4v-vIuDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b932f723-dac8-4993-ef48-b81b59e66bbf"
      },
      "source": [
        "#Your trained weights will be in this directory:\n",
        "%ls -l '/content/training/'"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 54556\n",
            "-rw-r--r-- 1 root root      255 Feb  2 06:23 checkpoint\n",
            "-rw-r--r-- 1 root root 18649306 Feb  2 06:19 ckpt-1.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    22263 Feb  2 06:19 ckpt-1.index\n",
            "-rw-r--r-- 1 root root 37130982 Feb  2 06:23 ckpt-2.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    41640 Feb  2 06:23 ckpt-2.index\n",
            "drwxr-xr-x 2 root root     4096 Feb  2 06:18 \u001b[0m\u001b[01;34mtrain\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnSEZIzl4M10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd27a43-67f4-412d-c3bc-7c1e64226254"
      },
      "source": [
        "#Run conversion script to save the retrained model:\n",
        "#Saved model will be in saved_model.pb file:\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = '/content/fine_tuned_model'\n",
        "\n",
        "#place the model weights you would like to export here\n",
        "last_model_path = '/content/training/'\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/training/\n",
            "2022-02-02 06:27:55.300221: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0202 06:27:55.797803 140577799800704 deprecation.py:619] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:28:05.970843 140577799800704 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:28:05.971297 140577799800704 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:28:05.971537 140577799800704 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:28:05.971748 140577799800704 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:28:05.971952 140577799800704 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0202 06:28:05.972163 140577799800704 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fd9c22617d0>, because it is not built.\n",
            "W0202 06:28:14.199000 140577799800704 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fd9c22617d0>, because it is not built.\n",
            "2022-02-02 06:28:23.837902: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "W0202 06:28:38.636408 140577799800704 save.py:268] Found untraced functions such as BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, BoxPredictor_layer_call_and_return_conditional_losses while saving (showing 5 of 125). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/fine_tuned_model/saved_model/assets\n",
            "I0202 06:28:43.608034 140577799800704 builder_impl.py:784] Assets written to: /content/fine_tuned_model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/fine_tuned_model/pipeline.config\n",
            "I0202 06:28:44.191666 140577799800704 config_util.py:254] Writing pipeline config file to /content/fine_tuned_model/pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsE_uVjlsz3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc93fa79-7708-4274-c51a-8e94f74f67ad"
      },
      "source": [
        "%ls '/content/fine_tuned_model/saved_model/'"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/  saved_model.pb  \u001b[01;34mvariables\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vz2vJeCCyZR"
      },
      "source": [
        "# Run Inference on Test Images with Custom TensorFlow2 Object Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcR4PWC3KBau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "defcba61-8ef9-41ef-bcdc-408442984ce3"
      },
      "source": [
        "#Import your test images to colab. I use pinterest to store the the images. \n",
        "%mkdir /content/test/\n",
        "%cd /content/test/\n",
        "#M&M toy:\n",
        "#!curl -L \"https://i.pinimg.com/originals/4c/6a/00/4c6a0021a735e1dcb9edcb6715467e15.jpg\" > test.jpeg;\n",
        "#Pickachu toy:\n",
        "!curl -L \"https://i.pinimg.com/564x/f5/46/c4/f546c47505e1f5f8d17f8458d641b262.jpg\" > test.jpeg;\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/test\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 66488  100 66488    0     0   532k      0 --:--:-- --:--:-- --:--:--  532k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxtm1NutE5vK"
      },
      "source": [
        "import os \n",
        "import glob\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFY75DfTDHaU"
      },
      "source": [
        "#Recover our saved model with the latest checkpoint:\n",
        "pipeline_config = pipeline_file\n",
        "#Put the last ckpt from training in here, don't use long pathnames:\n",
        "model_dir = '/content/training/ckpt-2'\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(\n",
        "      model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore last checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "      model=detection_model)\n",
        "#ckpt.restore(os.path.join(model_dir))\n",
        "ckpt.restore(model_dir)\n",
        "\n",
        "#Function perform detection of the object on image in tensor format: \n",
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "  @tf.function\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn\n",
        "  \n",
        "#Define function which performs detection: \n",
        "detect_fn = get_model_detection_function(detection_model)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ycfl7rnDT1D"
      },
      "source": [
        "#map labels for inference decoding\n",
        "label_map_path = configs['eval_input_config'].label_map_path\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map,\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "    use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN1BzORoIzV4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "a820c49e-7094-43ce-d5ca-191095376c4a"
      },
      "source": [
        "#run detector on test image\n",
        "#it takes a little longer on the first run and then runs at normal speed. \n",
        "import random\n",
        "\n",
        "#Define utility functions for presenting the results:\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "#Place your test images here:\n",
        "image_path = '/content/test/overlay.jpg'\n",
        "\n",
        "#Store test images in nmpy array:\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "#Convert images to tensor form:\n",
        "input_tensor = tf.convert_to_tensor(\n",
        "    np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "\n",
        "#Perform detection on the image in tensor format:\n",
        "detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "#Visualize the detection boxes on the image:\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'][0].numpy(),\n",
        "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
        "      detections['detection_scores'][0].numpy(),\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=0.70,#0.5,#0.5\n",
        "      agnostic_mode=False,\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12,16))\n",
        "plt.imshow(image_np_with_detections)\n",
        "plt.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-7c0c9aa7530d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#Perform detection on the image in tensor format:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#Visualize the detection boxes on the image:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Place your test images here:\n",
        "image_path = '/content/test/test.jpeg'\n",
        "\n",
        "#Store test images in nmpy array:\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "#Convert images to tensor form:\n",
        "input_tensor = tf.convert_to_tensor(\n",
        "    np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "\n",
        "#Perform detection on the image in tensor format:\n",
        "detections, predictions_dict, shapes = detect_fn(input_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "lxtvE8_SNcfE",
        "outputId": "94a9d065-44eb-4053-b0b4-24515e06b780"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-f2bb7a73b7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Perform detection on the image in tensor format:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_data = tf.io.gfile.GFile('/content/test/overlay.jpg', 'rb').read()\n",
        "image = Image.open(BytesIO(img_data))\n",
        "(im_width, im_height) = image.size\n",
        "np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkz2egTgJ94l",
        "outputId": "2709c752-1a71-4d45-c4ff-63b381eb08db"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[115, 114,  83],\n",
              "        [105, 104,  73],\n",
              "        [ 87,  86,  55],\n",
              "        ...,\n",
              "        [255, 220, 165],\n",
              "        [255, 217, 162],\n",
              "        [254, 215, 160]],\n",
              "\n",
              "       [[ 94,  93,  62],\n",
              "        [ 85,  84,  53],\n",
              "        [ 82,  81,  50],\n",
              "        ...,\n",
              "        [238, 222, 189],\n",
              "        [237, 221, 188],\n",
              "        [235, 219, 186]],\n",
              "\n",
              "       [[ 80,  79,  48],\n",
              "        [ 77,  76,  45],\n",
              "        [ 89,  88,  57],\n",
              "        ...,\n",
              "        [ 28,  33,  29],\n",
              "        [ 28,  33,  29],\n",
              "        [ 27,  32,  28]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 28,  52,  20],\n",
              "        [ 50,  74,  42],\n",
              "        [ 47,  71,  39],\n",
              "        ...,\n",
              "        [ 91, 114,  58],\n",
              "        [ 66,  89,  35],\n",
              "        [ 56,  79,  27]],\n",
              "\n",
              "       [[ 43,  67,  35],\n",
              "        [ 59,  83,  51],\n",
              "        [ 48,  72,  40],\n",
              "        ...,\n",
              "        [108, 131,  77],\n",
              "        [ 86, 109,  57],\n",
              "        [ 73,  95,  46]],\n",
              "\n",
              "       [[ 40,  64,  32],\n",
              "        [ 54,  78,  46],\n",
              "        [ 41,  65,  31],\n",
              "        ...,\n",
              "        [121, 141,  88],\n",
              "        [110, 130,  79],\n",
              "        [ 98, 118,  69]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVAthLKWOzIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1709f99c-a46d-4334-c38c-92ec5dd000f7"
      },
      "source": [
        "print(detections)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'detection_boxes': <tf.Tensor: shape=(1, 100, 4), dtype=float32, numpy=\n",
            "array([[[0.        , 0.5384983 , 0.8673439 , 1.        ],\n",
            "        [0.06221145, 0.0056223 , 0.8854016 , 0.25180617],\n",
            "        [0.38846886, 0.231343  , 0.79521966, 0.4667509 ],\n",
            "        [0.18573296, 0.59499484, 1.        , 1.        ],\n",
            "        [0.4002268 , 0.        , 0.998803  , 0.35892016],\n",
            "        [0.00523809, 0.        , 0.7317513 , 0.39898866],\n",
            "        [0.        , 0.44331908, 0.45566368, 1.        ],\n",
            "        [0.5748647 , 0.5584329 , 1.        , 0.9606729 ],\n",
            "        [0.        , 0.21766928, 0.6137232 , 1.        ],\n",
            "        [0.44021353, 0.1027469 , 1.        , 1.        ],\n",
            "        [0.45164448, 0.1844042 , 0.75729114, 0.5074981 ],\n",
            "        [0.44310138, 0.27960944, 0.96253586, 0.700312  ],\n",
            "        [0.05797669, 0.13167095, 0.7140225 , 0.83621466],\n",
            "        [0.37078822, 0.182004  , 0.6741077 , 0.52983606],\n",
            "        [0.36808866, 0.        , 0.9767062 , 0.13438487],\n",
            "        [0.        , 0.642269  , 0.6422963 , 0.9904635 ],\n",
            "        [0.14289826, 0.391904  , 0.83262116, 0.9471041 ],\n",
            "        [0.17348894, 0.8194736 , 0.9710165 , 1.        ],\n",
            "        [0.6500656 , 0.05564234, 0.789347  , 0.6033722 ],\n",
            "        [0.52211803, 0.10096218, 0.74281627, 0.583219  ],\n",
            "        [0.        , 0.8237109 , 0.767153  , 0.99747384],\n",
            "        [0.23316595, 0.05406541, 0.6950692 , 1.        ],\n",
            "        [0.447221  , 0.17028008, 0.69312763, 0.64212567],\n",
            "        [0.48836064, 0.6230583 , 1.        , 1.        ],\n",
            "        [0.02735198, 0.40792096, 0.28612316, 1.        ],\n",
            "        [0.3093143 , 0.37925753, 0.9393775 , 1.        ],\n",
            "        [0.09613647, 0.39645624, 0.3937893 , 1.        ],\n",
            "        [0.528437  , 0.78951526, 1.        , 1.        ],\n",
            "        [0.        , 0.845803  , 0.51776063, 1.        ],\n",
            "        [0.35348567, 0.26113743, 0.76263297, 0.5535139 ],\n",
            "        [0.5956801 , 0.18200496, 1.        , 0.5235126 ],\n",
            "        [0.        , 0.5941428 , 0.18395181, 1.        ],\n",
            "        [0.20966366, 0.23472986, 0.8624475 , 0.8208531 ],\n",
            "        [0.5752245 , 0.        , 0.9029794 , 0.375551  ],\n",
            "        [0.3068213 , 0.15723345, 0.76315564, 0.44722906],\n",
            "        [0.6733665 , 0.49535957, 0.9519442 , 1.        ],\n",
            "        [0.29261446, 0.        , 0.8353056 , 0.16535158],\n",
            "        [0.3826828 , 0.        , 1.        , 0.9139445 ],\n",
            "        [0.5042036 , 0.        , 1.        , 0.24007441],\n",
            "        [0.3002556 , 0.        , 0.68709916, 0.79225457],\n",
            "        [0.37821835, 0.11551178, 0.6044331 , 0.58553445],\n",
            "        [0.06966871, 0.50467134, 0.5749521 , 1.        ],\n",
            "        [0.        , 0.62272286, 0.45232546, 0.9047146 ],\n",
            "        [0.4372704 , 0.        , 0.866524  , 0.21404003],\n",
            "        [0.63883346, 0.        , 0.8634265 , 0.45772505],\n",
            "        [0.537724  , 0.        , 0.7990687 , 0.60702467],\n",
            "        [0.6176697 , 0.4480301 , 0.8791398 , 1.        ],\n",
            "        [0.46868992, 0.        , 0.8140626 , 0.33912408],\n",
            "        [0.36328858, 0.        , 0.6595227 , 0.644855  ],\n",
            "        [0.        , 0.67971   , 0.23670986, 1.        ],\n",
            "        [0.8809021 , 0.5110485 , 0.99115616, 1.        ],\n",
            "        [0.5273945 , 0.3396916 , 0.8486813 , 1.        ],\n",
            "        [0.424173  , 0.51902807, 0.8536663 , 1.        ],\n",
            "        [0.33619052, 0.32191315, 0.6598162 , 1.        ],\n",
            "        [0.01277815, 0.20230767, 0.45643204, 1.        ],\n",
            "        [0.63634765, 0.27366346, 0.98402345, 1.        ],\n",
            "        [0.1435743 , 0.        , 0.47496057, 0.645496  ],\n",
            "        [0.11578733, 0.18030784, 0.4861974 , 0.8330753 ],\n",
            "        [0.23301263, 0.        , 0.46392184, 0.47475556],\n",
            "        [0.54082364, 0.        , 0.7659399 , 0.4137747 ],\n",
            "        [0.        , 0.62310004, 0.26658508, 0.88219166],\n",
            "        [0.60632324, 0.04652597, 1.        , 0.4420423 ],\n",
            "        [0.14383182, 0.22004181, 0.77300763, 0.47211814],\n",
            "        [0.54976225, 0.14504248, 0.7997947 , 0.52318484],\n",
            "        [0.42089373, 0.44704294, 0.6839281 , 1.        ],\n",
            "        [0.35650894, 0.        , 0.63725495, 0.45888352],\n",
            "        [0.14760917, 0.        , 0.4489386 , 0.5092732 ],\n",
            "        [0.14599565, 0.4550413 , 0.45636007, 1.        ],\n",
            "        [0.34110785, 0.        , 0.5647381 , 0.43659788],\n",
            "        [0.5170708 , 0.27580822, 0.76750326, 0.45281565],\n",
            "        [0.515859  , 0.        , 0.78223825, 0.27930623],\n",
            "        [0.6151787 , 0.        , 0.8819226 , 0.2745086 ],\n",
            "        [0.21563537, 0.43156818, 0.47995192, 1.        ],\n",
            "        [0.32139304, 0.43968278, 0.58100986, 1.        ],\n",
            "        [0.4217034 , 0.22123912, 0.591567  , 0.50597656],\n",
            "        [0.45058239, 0.2921601 , 0.54733   , 0.39439893],\n",
            "        [0.16250068, 0.        , 0.52769196, 0.42256188],\n",
            "        [0.26751816, 0.        , 0.61760324, 0.36971372],\n",
            "        [0.67494434, 0.69468105, 0.9638943 , 1.        ],\n",
            "        [0.4085811 , 0.28983623, 0.4859992 , 0.4043799 ],\n",
            "        [0.73791456, 0.5457021 , 0.9942485 , 1.        ],\n",
            "        [0.24053441, 0.5026171 , 0.64717686, 1.        ],\n",
            "        [0.23942211, 0.        , 0.7727802 , 1.        ],\n",
            "        [0.41877544, 0.        , 0.6861057 , 0.27787653],\n",
            "        [0.45064384, 0.        , 0.6717209 , 0.41240436],\n",
            "        [0.4611653 , 0.22176449, 0.6479151 , 0.49947697],\n",
            "        [0.0458077 , 0.5968317 , 0.2595706 , 1.        ],\n",
            "        [0.5403655 , 0.41630572, 0.7692024 , 0.9596574 ],\n",
            "        [0.504089  , 0.29302514, 0.6041033 , 0.39507765],\n",
            "        [0.60866237, 0.34735453, 0.7118077 , 0.44805223],\n",
            "        [0.45197663, 0.24303077, 0.555349  , 0.3391286 ],\n",
            "        [0.75491536, 0.9491917 , 1.        , 0.99314547],\n",
            "        [0.52565473, 0.22981249, 0.6988959 , 0.4935463 ],\n",
            "        [0.        , 0.        , 0.28662425, 0.44624865],\n",
            "        [0.25278372, 0.        , 0.67034125, 0.21395417],\n",
            "        [0.6659329 , 0.34616774, 0.76783264, 0.44944036],\n",
            "        [0.44710246, 0.34820485, 0.5525236 , 0.4448576 ],\n",
            "        [0.7424088 , 0.64809835, 0.9432592 , 1.        ],\n",
            "        [0.53676575, 0.16013157, 0.8115048 , 0.72105706],\n",
            "        [0.3533274 , 0.14711148, 0.6398102 , 0.7629481 ]]], dtype=float32)>, 'detection_scores': <tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
            "array([[0.1814045 , 0.07653649, 0.07285509, 0.06328924, 0.0380794 ,\n",
            "        0.0319257 , 0.03170485, 0.02956221, 0.02589793, 0.02492676,\n",
            "        0.02448813, 0.02378868, 0.02345847, 0.02243624, 0.02008927,\n",
            "        0.01981238, 0.01877178, 0.01793603, 0.01707582, 0.01672802,\n",
            "        0.01652758, 0.01648006, 0.01643161, 0.01617688, 0.01494238,\n",
            "        0.01472383, 0.01385529, 0.01384313, 0.01366382, 0.01332207,\n",
            "        0.01331652, 0.01326868, 0.01326195, 0.01285599, 0.01258176,\n",
            "        0.01248592, 0.01248565, 0.01238709, 0.01219705, 0.01197125,\n",
            "        0.01196667, 0.01182503, 0.01147417, 0.01137386, 0.01117297,\n",
            "        0.01075875, 0.01071499, 0.0106307 , 0.01058853, 0.01058542,\n",
            "        0.01024061, 0.0101506 , 0.01010505, 0.00998845, 0.009928  ,\n",
            "        0.00991377, 0.00987414, 0.0098191 , 0.00971079, 0.0096565 ,\n",
            "        0.00963022, 0.00959603, 0.00959429, 0.00948977, 0.00943799,\n",
            "        0.00942301, 0.00927186, 0.00925801, 0.00914289, 0.00906218,\n",
            "        0.00899845, 0.00891136, 0.00883877, 0.0087845 , 0.00858827,\n",
            "        0.008542  , 0.00850813, 0.00848447, 0.00839715, 0.00838552,\n",
            "        0.00827961, 0.00823869, 0.00823195, 0.0082139 , 0.00815429,\n",
            "        0.00812646, 0.00811915, 0.00809652, 0.00803869, 0.00796843,\n",
            "        0.00787496, 0.00784662, 0.00783506, 0.00775582, 0.00768321,\n",
            "        0.00767266, 0.00765988, 0.0076512 , 0.00761523, 0.00761215]],\n",
            "      dtype=float32)>, 'detection_classes': <tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.]], dtype=float32)>, 'num_detections': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([100.], dtype=float32)>, 'raw_detection_boxes': <tf.Tensor: shape=(1, 1917, 4), dtype=float32, numpy=\n",
            "array([[[ 0.00904732, -0.00476509,  0.07536728,  0.08127462],\n",
            "        [-0.00465082, -0.0536117 ,  0.08179812,  0.17773427],\n",
            "        [-0.10931415,  0.02019579,  0.25757375,  0.07467699],\n",
            "        ...,\n",
            "        [ 0.23942211, -0.32403606,  0.7727802 ,  1.3204658 ],\n",
            "        [ 0.09208935,  0.18280965,  0.93706256,  0.8257367 ],\n",
            "        [ 0.02610481,  0.24965543,  0.6687294 ,  1.1789558 ]]],\n",
            "      dtype=float32)>, 'raw_detection_scores': <tf.Tensor: shape=(1, 1917, 2), dtype=float32, numpy=\n",
            "array([[[0.00456138, 0.00457451],\n",
            "        [0.00466197, 0.00407171],\n",
            "        [0.0043853 , 0.00410122],\n",
            "        ...,\n",
            "        [0.01230441, 0.00823195],\n",
            "        [0.0073294 , 0.00864885],\n",
            "        [0.006998  , 0.01343656]]], dtype=float32)>, 'detection_multiclass_scores': <tf.Tensor: shape=(1, 100, 2), dtype=float32, numpy=\n",
            "array([[[0.00996451, 0.1814045 ],\n",
            "        [0.00854441, 0.07653649],\n",
            "        [0.00903908, 0.07285509],\n",
            "        [0.00933014, 0.06328924],\n",
            "        [0.0083151 , 0.0380794 ],\n",
            "        [0.00847514, 0.0319257 ],\n",
            "        [0.0081143 , 0.03170485],\n",
            "        [0.00878487, 0.02956221],\n",
            "        [0.00785047, 0.02589793],\n",
            "        [0.00915941, 0.02492676],\n",
            "        [0.00912267, 0.02448813],\n",
            "        [0.00692334, 0.02378868],\n",
            "        [0.00934371, 0.02345847],\n",
            "        [0.00880094, 0.02243624],\n",
            "        [0.0095088 , 0.02008927],\n",
            "        [0.00879199, 0.01981238],\n",
            "        [0.01004824, 0.01877178],\n",
            "        [0.00762534, 0.01793603],\n",
            "        [0.00888958, 0.01707582],\n",
            "        [0.00914033, 0.01672802],\n",
            "        [0.00764456, 0.01652758],\n",
            "        [0.00825699, 0.01648006],\n",
            "        [0.00788981, 0.01643161],\n",
            "        [0.00828651, 0.01617688],\n",
            "        [0.00644056, 0.01494238],\n",
            "        [0.01041814, 0.01472383],\n",
            "        [0.00731008, 0.01385529],\n",
            "        [0.00748893, 0.01384313],\n",
            "        [0.00879571, 0.01366382],\n",
            "        [0.00862738, 0.01332207],\n",
            "        [0.0078004 , 0.01331652],\n",
            "        [0.00992663, 0.01326868],\n",
            "        [0.00691049, 0.01326195],\n",
            "        [0.00928617, 0.01285599],\n",
            "        [0.00889658, 0.01258176],\n",
            "        [0.00826721, 0.01248592],\n",
            "        [0.00781509, 0.01248565],\n",
            "        [0.00717876, 0.01238709],\n",
            "        [0.0104007 , 0.01219705],\n",
            "        [0.0083789 , 0.01197125],\n",
            "        [0.00895467, 0.01196667],\n",
            "        [0.00869008, 0.01182503],\n",
            "        [0.00627731, 0.01147417],\n",
            "        [0.00957327, 0.01137386],\n",
            "        [0.00751829, 0.01117297],\n",
            "        [0.00892283, 0.01075875],\n",
            "        [0.00884422, 0.01071499],\n",
            "        [0.0089845 , 0.0106307 ],\n",
            "        [0.00873196, 0.01058853],\n",
            "        [0.01000056, 0.01058542],\n",
            "        [0.00785694, 0.01024061],\n",
            "        [0.00942734, 0.0101506 ],\n",
            "        [0.00854937, 0.01010505],\n",
            "        [0.00960082, 0.00998845],\n",
            "        [0.00755867, 0.009928  ],\n",
            "        [0.00739709, 0.00991377],\n",
            "        [0.00774667, 0.00987414],\n",
            "        [0.0070607 , 0.0098191 ],\n",
            "        [0.00782015, 0.00971079],\n",
            "        [0.00806508, 0.0096565 ],\n",
            "        [0.00631865, 0.00963022],\n",
            "        [0.00810312, 0.00959603],\n",
            "        [0.00806261, 0.00959429],\n",
            "        [0.00724598, 0.00948977],\n",
            "        [0.00881938, 0.00943799],\n",
            "        [0.00957151, 0.00942301],\n",
            "        [0.0099547 , 0.00927186],\n",
            "        [0.00947546, 0.00925801],\n",
            "        [0.00848511, 0.00914289],\n",
            "        [0.00753665, 0.00906218],\n",
            "        [0.00946455, 0.00899845],\n",
            "        [0.00910472, 0.00891136],\n",
            "        [0.0084431 , 0.00883877],\n",
            "        [0.00876223, 0.0087845 ],\n",
            "        [0.00745447, 0.00858827],\n",
            "        [0.00830921, 0.008542  ],\n",
            "        [0.00789795, 0.00850813],\n",
            "        [0.0087089 , 0.00848447],\n",
            "        [0.00891812, 0.00839715],\n",
            "        [0.00690857, 0.00838552],\n",
            "        [0.00724077, 0.00827961],\n",
            "        [0.0085486 , 0.00823869],\n",
            "        [0.01230441, 0.00823195],\n",
            "        [0.00955151, 0.0082139 ],\n",
            "        [0.00807278, 0.00815429],\n",
            "        [0.00744146, 0.00812646],\n",
            "        [0.0081526 , 0.00811915],\n",
            "        [0.00800193, 0.00809652],\n",
            "        [0.00785886, 0.00803869],\n",
            "        [0.00756598, 0.00796843],\n",
            "        [0.00738792, 0.00787496],\n",
            "        [0.00486176, 0.00784662],\n",
            "        [0.00761839, 0.00783506],\n",
            "        [0.00899251, 0.00775582],\n",
            "        [0.00905444, 0.00768321],\n",
            "        [0.00763703, 0.00767266],\n",
            "        [0.00673876, 0.00765988],\n",
            "        [0.00866248, 0.0076512 ],\n",
            "        [0.00766963, 0.00761523],\n",
            "        [0.00750978, 0.00761215]]], dtype=float32)>, 'detection_anchor_indices': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
            "array([[1742, 1747, 1403, 1802, 1514, 1274, 1190, 1610, 1706, 1908, 1462,\n",
            "        1875, 1894, 1342, 1447, 1255, 1897, 1441, 1524, 1464, 1321, 1860,\n",
            "        1410, 1611, 1188, 1905, 1248, 1619, 1201, 1352, 1581, 1132, 1857,\n",
            "        1510, 1340, 1606, 1385, 1902, 1508, 1854, 1344, 1738, 1189, 1443,\n",
            "        1512, 1782, 1548, 1450, 1752, 1131, 1674, 1794, 1486, 1764, 1702,\n",
            "        1878, 1722, 1728, 1272, 1452, 1127, 1580, 1285, 1522, 1428, 1746,\n",
            "        1716, 1740, 1332,  764, 1444, 1504, 1308, 1368,  535,  531, 1270,\n",
            "        1330, 1618,  474, 1830, 1366, 1914, 1384, 1392,  592, 1200, 1482,\n",
            "         588,  705,  528, 1025,  649, 1686, 1323,  762,  534, 1620, 1788,\n",
            "        1758]], dtype=int32)>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ-N94cKB82o"
      },
      "source": [
        "# Congrats!\n",
        "Hope you enjoyed this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGtjyg-JVX6S"
      },
      "source": [
        "# Bonus level:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Bhr6Dj8Ts--"
      },
      "source": [
        "To use this retrained model in web browser run the following commands:\n",
        "\n",
        "For details see my article on medium: \n",
        "\n",
        "\"[Build custom object detection web application using TensorFlow.js](https://kostya-malsev.medium.com/build-custom-object-detection-web-application-using-tensorflow-js-d1664f96a18b)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvBgk8u-DWkT"
      },
      "source": [
        "!saved_model_cli show --dir /content/fine_tuned_model/saved_model/ --tag_set serve --signature_def serving_default\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4e8A__DN92x"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsuTSt7YL4OL"
      },
      "source": [
        "!tensorflowjs_converter  \\\n",
        "--input_format=tf_saved_model\\\n",
        " --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores'\\\n",
        "  --saved_model_tags=serve\\\n",
        "   --output_format=tfjs_graph_model /content/fine_tuned_model/saved_model /content/fine_tuned_model/web_model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2m-6PXgKa5-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fa846ae0-6d32-47cf-d90c-3e4698c56b24"
      },
      "source": [
        "!ls /content/fine_tuned_model/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  pipeline.config  saved_model  web_model\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}